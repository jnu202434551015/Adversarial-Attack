# Adversarial-Attack
Adversarial-Attack-Deepfake

* Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples [[PDF]](http://openaccess.thecvf.com/content/WACV2021/papers/Hussain_Adversarial_Deepfakes_Evaluating_Vulnerability_of_Deepfake_Detectors_to_Adversarial_Examples_WACV_2021_paper.pdf)
* [Hussain, S., Neekhara, P., Jere, M., Koushanfar, F., & McAuley, J. (2021). Adversarial deepfakes: Evaluating vulnerability of deepfake detectors to adversarial examples. In Proceedings of the IEEE/CVF winter conference on applications of computer vision (pp. 3348-3357).]
* Thinking Racial Bias in Fair Forgery Detection: Models, Datasets and Evaluations [[PDF]](https://ojs.aaai.org/index.php/AAAI/article/view/32572/34727)
* [Liu, D., Wang, Z., Peng, C., Wang, N., Hu, R., & Gao, X. (2025, April). Thinking racial bias in fair forgery detection: Models, datasets and evaluations. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 5, pp. 5379-5387).]
* AI-Face: A Million-Scale Demographically Annotated AI-Generated Face Dataset and Fairness Benchmark [[PDF]](https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AI-Face_A_Million-Scale_Demographically_Annotated_AI-Generated_Face_Dataset_and_Fairness_CVPR_2025_paper.pdf) [[code]](https://github.com/Purdue-M2/AI-Face-FairnessBench)
* [Lin, L., Santosh, S., Wu, M., Wang, X., & Hu, S. (2025). Ai-face: A million-scale demographically annotated ai-generated face dataset and fairness benchmark. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 3503-3515).]

## Fairness-enhanced Model
* Improving Fairness in Deepfake Detection [[PDF]](https://openaccess.thecvf.com/content/WACV2024/papers/Ju_Improving_Fairness_in_Deepfake_Detection_WACV_2024_paper.pdf)
* [Ju, Y., Hu, S., Jia, S., Chen, G. H., & Lyu, S. (2024). Improving fairness in deepfake detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 4655-4665).]
* Preserving Fairness Generalization in Deepfake Detection [[PDF]](https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_Preserving_Fairness_Generalization_in_Deepfake_Detection_CVPR_2024_paper.pdf) [[code]](https://github.com/Purdue-M2/Fairness-Generalization)
* [Lin, L., He, X., Ju, Y., Wang, X., Ding, F., & Hu, S. (2024). Preserving fairness generalization in deepfake detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 16815-16825).]

## Attack - Deepfake
* Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of AI-Generated Media (AADD-2025) [[PDF]](https://dl.acm.org/doi/pdf/10.1145/3746027.3761983) [[code]](https://github.com/mfs-iplab/aadd-2025)
* [Battiato, S., Casu, M., Guarnera, F., Guarnera, L., Puglisi, G., Pontorno, O., ... & Akhtar, Z. (2025, October). Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of AI-Generated Media (AADD-2025). In Proceedings of the 33rd ACM International Conference on Multimedia (pp. 13714-13719).]
* MIG-COW: Transferable Adversarial Attacks on Deepfake Detectors via Gradient Decomposition [[PDF]](https://dl.acm.org/doi/pdf/10.1145/3746027.3761986)
* [Seo, W., Baek, J., Jung, Y., & Park, S. (2025, October). MIG-COW: Transferable Adversarial Attacks on Deepfake Detectors via Gradient Decomposition. In Proceedings of the 33rd ACM International Conference on Multimedia (pp. 13730-13736).]
* ADVERSARIAL LATENT FEATURE AUGMENTATION FOR FAIRNESS [[PDF]](https://openreview.net/pdf?id=cNaHOdvh9J) [[code]](https://github.com/HoinJung/Adversarial-Latent-Feature-Augmentation-Fairness)
* [Jung, H., Chai, J., & Wang, X. (2025). Adversarial Latent Feature Augmentation for Fairness. In The Thirteenth International Conference on Learning Representations.]
* Spectrum Translation for Refinement of Image Generation (STIG) Based on Contrastive Learning and Spectral Filter Profile [[PDF]](https://ojs.aaai.org/index.php/AAAI/article/view/28074/28154)
* [Lee, S., Jung, S. W., & Seo, H. (2024, March). Spectrum translation for refinement of image generation (STIG) based on contrastive learning and spectral filter profile. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 38, No. 4, pp. 2929-2937).]
* Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces [[PDF]](https://openaccess.thecvf.com/content/CVPR2023/papers/Shamshad_Evading_Forensic_Classifiers_With_Attribute-Conditioned_Adversarial_Faces_CVPR_2023_paper.pdf)
* [Shamshad, F., Srivatsan, K., & Nandakumar, K. (2023). Evading forensic classifiers with attribute-conditioned adversarial faces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 16469-16478).]
* Open-Unfairness Adversarial Mitigation for Generalized Deepfake Detection [[PDF]](https://openaccess.thecvf.com/content/ICCV2025/papers/Li_Open-Unfairness_Adversarial_Mitigation_for_Generalized_Deepfake_Detection_ICCV_2025_paper.pdf)
* [Li, Z., Teng, Z., Zhang, B., & Fan, J. (2025). Open-Unfairness Adversarial Mitigation for Generalized Deepfake Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 698-707).]
* Adversarial Reality for Evading Deepfake Image Detectors [[PDF]](https://openaccess.thecvf.com/content/ICCV2025W/APAI/papers/Ciftci_Adversarial_Reality_for_Evading_Deepfake_Image_Detectors_ICCVW_2025_paper.pdf)
* [Ciftci, U. A., Solar, N., Greene, E., Saremsky, S. R., & Demir, I. (2025). Adversarial Reality for Evading Deepfake Image Detectors. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 1607-1618).]
* AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection [[PDF]](https://arxiv.org/pdf/2312.08675)[[code]](https://github.com/AnonymousUserA/AVA)
* [Meng, X., Wang, L., Guo, S., Ju, L., & Zhao, Q. (2024, May). Ava: Inconspicuous attribute variation-based adversarial attack bypassing deepfake detection. In 2024 IEEE Symposium on Security and Privacy (SP) (pp. 74-90). IEEE.]
* StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model [[PDF]](https://dl.acm.org/doi/pdf/10.1145/3664647.3681535?casa_token=IUs-9nw5zgoAAAAA:CfVywyX1FOauGKvwjfRiV9TzhPLSVOj5ySXaUklt8y3h8zwZIoMHA-oxHnjLeoeZzUL_EtFIAGfOww)[[code]](https://github.com/wyczzy/StealthDiffusion)
* [Zhou, Z., Sun, K., Chen, Z., Kuang, H., Sun, X., & Ji, R. (2024, October). Stealthdiffusion: Towards evading diffusion forensic detection through diffusion model. In Proceedings of the 32nd ACM International Conference on Multimedia (pp. 3627-3636).]
* Evading DeepFake Detectors via Adversarial Statistical Consistency [[PDF]](http://openaccess.thecvf.com/content/CVPR2023/papers/Hou_Evading_DeepFake_Detectors_via_Adversarial_Statistical_Consistency_CVPR_2023_paper.pdf)[[code]](https://github.com/tobuta/evadingfakedetector)
* [Hou, Y., Guo, Q., Huang, Y., Xie, X., Ma, L., & Zhao, J. (2023). Evading deepfake detectors via adversarial statistical consistency. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 12271-12280).]
* Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering [[PDF]](https://arxiv.org/pdf/2009.09213)[[code]](https://github.com/fanoflck/Implicit-spatial-notch)
* [Huang, Y., Juefei-Xu, F., Guo, Q., Liu, Y., & Pu, G. (2023). Dodging deepfake detection via implicit spatial-domain notch filtering. IEEE Transactions on Circuits and Systems for Video Technology, 34(8), 6949-6962.]
* Making DeepFakes more spurious: evading deep face forgery detection via trace removal attack [[PDF]](https://arxiv.org/pdf/2203.11433)
* [Liu, C., Chen, H., Zhu, T., Zhang, J., & Zhou, W. (2023). Making DeepFakes more spurious: evading deep face forgery detection via trace removal attack. IEEE Transactions on Dependable and Secure Computing, 20(6), 5182-5196.]
* Benchmarking Adversarial Robustness on Image Classification [[PDF]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_Benchmarking_Adversarial_Robustness_on_Image_Classification_CVPR_2020_paper.pdf)[[code]](https://github.com/thu-ml/ares)
* [Dong, Y., Fu, Q. A., Yang, X., Pang, T., Su, H., Xiao, Z., & Zhu, J. (2020). Benchmarking adversarial robustness on image classification. In proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 321-331).]

## Attack - Other
* Non-Adaptive Adversarial Face Generation [[PDF]](https://arxiv.org/pdf/2507.12107?)
* [NIPS 2025]
* CosPGD: an efficient white-box adversarial attack for pixel-wise prediction tasks [[PDF]](https://arxiv.org/pdf/2302.02213)
* [ICML 2024]
* MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework [[PDF]](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MOS-Attack_A_Scalable_Multi-objective_Adversarial_Attack_Framework_CVPR_2025_paper.pdf) [[code]](https://github.com/pgg3/MOS-Attack)
* [Guo, P., Gong, C., Lin, X., Liu, F., Lu, Z., Zhang, Q., & Wang, Z. (2025). MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 5041-5051).]
* ProjAttacker: A Configurable Physical Adversarial Attack for Face Recognition via Projector [[PDF]](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_ProjAttacker_A_Configurable_Physical_Adversarial_Attack_for_Face_Recognition_via_CVPR_2025_paper.pdf)
* [Liu, Y., Wei, H., Jia, C., Xiao, R., Ruan, W., Wei, X., ... & Wang, Z. (2025). ProjAttacker: A Configurable Physical Adversarial Attack for Face Recognition via Projector. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 21248-21257).]
* Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks [[PDF]](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adv-CPG_A_Customized_Portrait_Generation_Framework_with_Facial_Adversarial_Attacks_CVPR_2025_paper.pdf)
* [Wang, J., Zhang, H., & Yuan, Y. (2025). Adv-cpg: A customized portrait generation framework with facial adversarial attacks. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 21001-21010).]
* Improving the Transferability of Adversarial Attacks on Face Recognition with Diverse Parameters Augmentation [[PDF]](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Improving_the_Transferability_of_Adversarial_Attacks_on_Face_Recognition_with_CVPR_2025_paper.pdf)
* [Zhou, F., Yin, B., Ling, H., Zhou, Q., & Wang, W. (2025). Improving the Transferability of Adversarial Attacks on Face Recognition with Diverse Parameters Augmentation. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 3516-3527).]
* [[Link]](https://blog.csdn.net/qq_60090693/article/details/149852204)
* TraceEvader: Making DeepFakes More Untraceable via Evading the Forgery Model Attribution [[PDF]](https://ojs.aaai.org/index.php/AAAI/article/download/29973/31705)
* [Wu, M., Ma, J., Wang, R., Zhang, S., Liang, Z., Li, B., ... & Wang, L. (2024, March). Traceevader: Making deepfakes more untraceable via evading the forgery model attribution. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 38, No. 18, pp. 19965-19973).]
* Rethinking Impersonation and Dodging Attacks on Face Recognition Systems [[PDF]](https://dl.acm.org/doi/pdf/10.1145/3664647.3681440?casa_token=EFpWg1Hq8fwAAAAA:VJY953Tt7mTSGD3SOR5zUkje8gJCzkUnAMIogTmZOf0ZPnov46pfcg57ZbTbWE1LBa7evnONgHiVVQ)
* [Zhou, F., Zhou, Q., Yin, B., Zheng, H., Lu, X., Ma, L., & Ling, H. (2024, October). Rethinking impersonation and dodging attacks on face recognition systems. In Proceedings of the 32nd ACM International Conference on Multimedia (pp. 2487-2496).]
* Adversarial Attention Perturbations for Large Object Detection Transformers [[PDF]](https://openaccess.thecvf.com/content/ICCV2025/papers/Yahn_Adversarial_Attention_Perturbations_for_Large_Object_Detection_Transformers_ICCV_2025_paper.pdf)
* [Yahn, Z., Tekin, S. F., Ilhan, F., Hu, S., Huang, T., Xu, Y., ... & Liu, L. (2025). Adversarial Attention Perturbations for Large Object Detection Transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 3184-3193).]

## Sample
* Influence-Based Fair Selection for Sample-Discriminative Backdoor Attack [[PDF]](https://ojs.aaai.org/index.php/AAAI/article/view/35449/37604)
* [Wei, Q., He, S., Zhang, J., Feng, L., & An, B. (2025, April). Influence-Based Fair Selection for Sample-Discriminative Backdoor Attack. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 39, No. 20, pp. 21474-21481).]
* Revisiting model fairness via adversarial examples [[PDF]](https://www.sciencedirect.com/science/article/pii/S0950705123005270?casa_token=Rg0mPO5A32EAAAAA:pdnjwnuRjF_H3C2hw0WMzbjSvbuW8CGzjisHNbHrPU8UrPTNRQR8gm_B87N7LTc83dZVB7vr_CA) [[code]](https://github.com/TaocsZhang/Fairness-Attack-via-Adversarial-Examples)
* [Zhang, T., Zhu, T., Li, J., Zhou, W., & Yu, P. S. (2023). Revisiting model fairness via adversarial examples. Knowledge-Based Systems, 277, 110777.]
* Enhancing the Power of OOD Detection via Sample-Aware Model Selection [[PDF]](https://openaccess.thecvf.com/content/CVPR2024/papers/Xue_Enhancing_the_Power_of_OOD_Detection_via_Sample-Aware_Model_Selection_CVPR_2024_paper.pdf)
* [Xue, F., He, Z., Zhang, Y., Xie, C., Li, Z., & Tan, F. (2024). Enhancing the power of ood detection via sample-aware model selection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 17148-17157).]
